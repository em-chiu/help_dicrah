{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gensim \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "from  nltk.stem.snowball import FrenchStemmer, EnglishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import pickle\n",
    "import dill as pickle\n",
    "import unidecode\n",
    "import sys\n",
    "from help_dicrah_functions import *\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# ML Tools\n",
    "from sklearn import preprocessing, linear_model, svm, model_selection, ensemble\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, make_scorer\n",
    "\n",
    "import time\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "import os\n",
    "data_dir = '../data/'\n",
    "models_dir = '/Volumes/MIchi Hard /models/' #'../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following global variables to choose the type of processing and set output file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = True\n",
    "remove_sw = True\n",
    "\n",
    "if stem:\n",
    "    stem_str = '_with_stem'\n",
    "else:\n",
    "    stem_str = '_no_stem'\n",
    "\n",
    "    \n",
    "if remove_sw:\n",
    "    sw_str = '_sw_removed'\n",
    "else:\n",
    "    sw_str = '_no_sw_removed'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the sample to train w2v vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate time to clean the full sample (don't run, just for info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6c270a4c0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6c270a820>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6c270ab20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Sample size')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 't [sec.]')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb6c2720610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated time for 1M rows, tweet_cleaner = 4.520775520775521 min\n",
      "estimated time for 1M rows,tweet_cleaner+stemming = 10.00117821992822 min\n",
      "estimated time for 1M rows, tweet_cleaner+stemming+remove_stopwords = 17.26752818940319 min\n"
     ]
    }
   ],
   "source": [
    "dt1=[]\n",
    "dt2=[]\n",
    "dt3=[]\n",
    "N = range(100,3000,500)\n",
    "\n",
    "or_fname = 'Tweets_COVID19_France.csv'\n",
    "fname = data_dir+or_fname\n",
    "\n",
    "df = pd.read_csv(fname, header=None)\\\n",
    "        .drop(0, axis=1)\\\n",
    "        .rename(columns={1: 'tweet'})\n",
    "\n",
    "\n",
    "\n",
    "for n in N:\n",
    "    dg=df.loc[:n]\n",
    "    #dg = df.sample(n)\n",
    "\n",
    "    # cleaning with tweet_cleaner\n",
    "    t1 = current_milli_time()\n",
    "    dg['clean_tweets'] = dg.tweet.apply(\\\n",
    "                                     lambda x:tweet_cleaner(x, my_dict, stem=False))\n",
    "    \n",
    "    # cleaning with tweet_cleaner + stemming\n",
    "    t2 = current_milli_time()\n",
    "    dg['clean_tweets_sw'] = dg.tweet.apply(\\\n",
    "                                           lambda x:tweet_cleaner(text, my_dict, stem=True))\n",
    "    \n",
    "    # cleaning with tweet_cleaner + stemming + removing stopwords\n",
    "    t3 = current_milli_time()\n",
    "    dg['clean_tweets_sw_stem'] = dg.tweet.apply(\n",
    "        lambda x:' '.join(remove_stopwords(\n",
    "                        tokenize(\n",
    "                        tweet_cleaner(\n",
    "                            text,\n",
    "                            my_dict,\n",
    "                            stem=True)),\n",
    "                    generate_stopwords())))\n",
    "    t4 = current_milli_time()\n",
    "\n",
    "    dt1.append(t2-t1)\n",
    "    dt2.append(t3-t2)\n",
    "    dt3.append(t4-t3)\n",
    "\n",
    "\n",
    "plt.plot(N, dt1, 'r', label='tweet_cleaner');\n",
    "plt.plot(N, dt2, 'b', label='tweet_cleaner with stemming') ;\n",
    "plt.plot(N, dt3, 'g', label='tweet_cleaner with stemming and removing stopwords');\n",
    "plt.xlabel('Sample size');\n",
    "plt.ylabel('t [sec.]');\n",
    "plt.legend();\n",
    "plt.show();\n",
    "\n",
    "print(\"estimated time for 1M rows, tweet_cleaner =\", 1000*np.mean(np.array(dt1)/np.array(N))/60,\"min\")\n",
    "print(\"estimated time for 1M rows,tweet_cleaner+stemming =\", 1000*np.mean(np.array(dt2)/np.array(N))/60,\"min\")\n",
    "print(\"estimated time for 1M rows, tweet_cleaner+stemming+remove_stopwords =\", 1000*np.mean(np.array(dt3)/np.array(N))/60,\"min\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       tweet                    2  \\\n",
       "0                  Datetime             id_tweet   \n",
       "1       2020-04-28 08:45:41  1255055575207030791   \n",
       "2       2020-05-04 06:18:22  1257192827513196545   \n",
       "3       2020-04-27 13:33:48  1254765691984478208   \n",
       "4       2020-04-30 11:53:41  1255827660359569410   \n",
       "...                     ...                  ...   \n",
       "259730  2020-05-03 12:09:14  1256918739418861569   \n",
       "259731  2020-04-26 18:54:57  1254484124582187009   \n",
       "259732  2020-05-03 19:56:27  1257036319601102849   \n",
       "259733  2020-05-04 14:39:39  1257318980089286662   \n",
       "259734  2020-04-28 18:10:09  1255197627542646789   \n",
       "\n",
       "                                                        3  \n",
       "0                                                   tweet  \n",
       "1       Heureusement que le c√¥t√© Compassion et Pratiqu...  \n",
       "2       #immobilier #COVID2019 #CoronavirusFrance #loc...  \n",
       "3       RT @MathildePanot: üö® Parce qu‚Äôil existe une al...  \n",
       "4       RT @AntoineMaes: Le @RCLens qui gal√®re √† monte...  \n",
       "...                                                   ...  \n",
       "259730  RT @DrJacquesDurand: Des laissez passer \"COVID...  \n",
       "259731  Le point en @NvelleAquitaine avec les chiffres...  \n",
       "259732  RT @mselon3: #coronavirus, √©tat d'urgence sani...  \n",
       "259733  üáÆüá∑Lutte contre le #covid19: Les autorit√©s iran...  \n",
       "259734  RT @F3PaysdelaLoire: #Coronavirus : l'#√©pid√©mi...  \n",
       "\n",
       "[259735 rows x 3 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at data\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing: example of usage and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      " En effet, il a pas c√©l√©br√© https://t.co/fhwjTEyhMV \n",
      "\n",
      "tweet_cleaner (no stemming): \n",
      " en effet il a pas celebre \n",
      "\n",
      "tweet_cleaner (with stemming): \n",
      " en effet il a pas celebr \n",
      "\n",
      "tweet_cleaner (with stemming) +  remove_stopwords: \n",
      " e  e f f e    p  e e b r \n",
      "\n",
      "Tokenization: \n",
      " ['e', 'n', '', 'e', 'f', 'f', 'e', 't', '', 'i', 'l', '', 'a', '', 'p', 'a', 's', '', 'c', 'e', 'l', 'e', 'b', 'r', 'e'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'En effet, il a pas c√©l√©br√© https://t.co/fhwjTEyhMV'\n",
    "print(\"Original: \\n %s \\n\" %text)\n",
    "t1 = tweet_cleaner(text, my_dict)\n",
    "print(\"tweet_cleaner (no stemming): \\n %s \\n\" %t1)\n",
    "t2 = tweet_cleaner(text, my_dict, stem=True)\n",
    "print(\"tweet_cleaner (with stemming): \\n %s \\n\" %t2)\n",
    "t3 = ' '.join(remove_stopwords(\n",
    "                        tokenize(\n",
    "                        tweet_cleaner(\n",
    "                            text,\n",
    "                            my_dict,\n",
    "                            stem=True)),\n",
    "                    generate_stopwords()))\n",
    "print(\"tweet_cleaner (with stemming) +  remove_stopwords: \\n %s \\n\" %t3)\n",
    "t4 = tokenize(tweet_cleaner(text, my_dict))\n",
    "print(\"Tokenization: \\n %s \\n\" %t4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the full sample and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: ../data/Tweets_COVID19_France_with_stem_sw_removed.csv\n",
      "Loading clean dataset....\n",
      "(0, 5)\n",
      "CPU times: user 9.58 ms, sys: 3.37 ms, total: 12.9 ms\n",
      "Wall time: 15.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, tweet, 2, 3, clean_tweets]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# in the file name, inlcude the type of pre-processing used! It must be the same as\n",
    "# the one used to clean the labeled dataset\n",
    "base_fname = 'Tweets_COVID19_France'\n",
    "out_fname = base_fname+stem_str+sw_str+'.csv'\n",
    "\n",
    "SAVED_DATASET = data_dir+out_fname\n",
    "\n",
    "print(\"Path: \"+SAVED_DATASET)\n",
    "\n",
    "if not os.path.exists(SAVED_DATASET):\n",
    "    \n",
    "    print(\"Must clean dataset. Loading original...\")\n",
    "    \n",
    "    or_fname = 'Tweets_COVID19_France.csv'\n",
    "    fname = data_dir+or_fname\n",
    "\n",
    "    df = pd.read_csv(fname, header=None)\\\n",
    "        .drop(0, axis=1)\\\n",
    "        .rename(columns={1: 'tweet'})\n",
    "\n",
    "  \n",
    "    print(\"Cleaning dataset....\")\n",
    "\n",
    "    # takes ~10 mins to run\n",
    "    if not remove_sw:\n",
    "        df['clean_tweets'] = df.tweet.apply(lambda x:tweet_cleaner(x, my_dict, stem=stem)) \n",
    "    else:\n",
    "        # takes ~20 mins to run\n",
    "        df['clean_tweets'] = df.tweet.apply(lambda x:' '.join(remove_stopwords(\n",
    "                        tokenize(\n",
    "                        tweet_cleaner(\n",
    "                            x,\n",
    "                            my_dict,\n",
    "                            stem=stem)),\n",
    "                    generate_stopwords())))\n",
    "    \n",
    "    df = df.drop_duplicates(subset='clean_tweets')\n",
    "    df.to_csv(SAVED_DATASET)\n",
    "\n",
    "else:\n",
    "    print(\"Loading clean dataset....\")\n",
    "    df = pd.read_csv(SAVED_DATASET)    \n",
    "    # Apparently, some entries were saved as float (?). This function gest rid of the problem.\n",
    "    def to_string(text):\n",
    "        if type(text)==float:\n",
    "            text = str(text)\n",
    "        return text\n",
    "\n",
    "    df['clean_tweets'] = df.clean_tweets.apply(lambda row: to_string(row))\n",
    "\n",
    "    # Drop tweets with less than 2 words\n",
    "    df['nc'] = [len(t) for t in df.clean_tweets]\n",
    "    df['n_word'] = df['clean_tweets'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df.drop(df[df.nc <= 3].index).drop('nc', axis=1)\n",
    "    df = df.drop(df[df.n_word <= 3].index).drop('n_word', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w2v vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Volumes/MIchi Hard /models/saved_w2vec_1M_with_stem_sw_removed_nf300_mvc1_cont10.pkl\n",
      "Traning model....\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecTrainables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashfxn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         super(Word2Vec, self).__init__(\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             self.train(\n\u001b[0m\u001b[1;32m    747\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m         return super(Word2Vec, self).train(\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_training_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         return super(BaseWordEmbeddingsModel, self).train(\n\u001b[0m\u001b[1;32m   1064\u001b[0m             \u001b[0mdata_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         self._check_training_sanity(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parameters for w2v\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "#downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "base_model_name = 'saved_w2vec_1M'\n",
    "full_model_name = base_model_name+stem_str+sw_str\n",
    "\n",
    "SAVED_MODEL = models_dir+full_model_name+'_nf'+str(num_features)+'_mvc'+str(min_word_count)\\\n",
    "            +'_cont'+str(context)+'.pkl'#+'_ds'+str(downsampling)\n",
    "\n",
    "print(\"Path: \"+SAVED_MODEL)\n",
    "\n",
    "if not os.path.exists(SAVED_MODEL):\n",
    "    print(\"Traning model....\")\n",
    "    \n",
    "    # Prepare a list of tokens as input for w2v\n",
    "    documents = [tweet.split() for tweet in list(df['clean_tweets'])]\n",
    "    # Takes ~8 mins to train with 300 features\n",
    "    model_1M = gensim.models.Word2Vec(documents, \n",
    "                                      size=num_features, \n",
    "                                      window=context, \n",
    "                                      min_count=min_word_count,\n",
    "                                      workers=4)\n",
    "    model_1M.train(documents, total_examples=len(documents), epochs=10)\n",
    "    with open(SAVED_MODEL, \"wb\") as f:\n",
    "        pickle.dump(model_1M, f)\n",
    "else:\n",
    "    print(\"Loading model....\")\n",
    "    with open(SAVED_MODEL, \"rb\") as f:\n",
    "        model_1M = pickle.load(f)\n",
    "        \n",
    "w2v_1M = dict(zip(model_1M.wv.index2word, model_1M.wv.syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit tfIdf vectorizer to weight w2v vectors (SLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Volumes/MIchi Hard /models/saved_w2vec_1M_vectorizer_with_stem_sw_removed_nf300_mvc1_cont10.pkl\n",
      "Training vectorizer...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w2v_1M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v_1M' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_vec_name = 'saved_w2vec_1M_vectorizer'\n",
    "full_vec_name = base_vec_name+stem_str+sw_str\n",
    "\n",
    "\n",
    "SAVED_1M_VEC= models_dir+full_vec_name+'_nf'+str(num_features)+'_mvc'+str(min_word_count)\\\n",
    "            +'_cont'+str(context)+'.pkl'#+'_ds'+str(downsampling)\n",
    "\n",
    "print('Path: '+SAVED_1M_VEC)    \n",
    "    \n",
    "if not os.path.exists(SAVED_1M_VEC):\n",
    "\n",
    "        print(\"Training vectorizer...\")\n",
    "        # building 1M vectorizer\n",
    "        # Takes ~20 mins to train\n",
    "        my_vectorizer_1M = TfidfEmbeddingVectorizer(w2v_1M)\n",
    "        if remove_sw:\n",
    "            my_vectorizer_1M.fit(df.clean_tweets, stem=stem, rem_sw=True)\n",
    "        else:\n",
    "            my_vectorizer_1M.fit(df.clean_tweets, stem=stem, rem_sw=False)\n",
    "                \n",
    "        with open(SAVED_1M_VEC, \"wb\") as f:\n",
    "            pickle.dump(my_vectorizer_1M, f)\n",
    "\n",
    "else:\n",
    "        print(\"Loading vectorizer...\")\n",
    "        with open(SAVED_1M_VEC, \"rb\") as f:\n",
    "            my_vectorizer_1M = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    3057\n",
       "0.0     543\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>ID</th>\n",
       "      <th>Texte</th>\n",
       "      <th>Texte_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>998206424189751296</td>\n",
       "      <td>On m‚Äôavait sorti (pour de vrai) ¬´¬†on est tous ...</td>\n",
       "      <td>v  r  p u r  e  v r   e  u  e g   p u   p r ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>997896508384169984</td>\n",
       "      <td>VIVE L AMOUR ‚ù§VIVE LA PAIX\\n‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§üëèüëç\\nEN...</td>\n",
       "      <td>v v   u r  v v   p x  e r e  e  p e u p  u   p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>J'me rend compte √† quel point ya trop d'noir d...</td>\n",
       "      <td>e  r e  p   q u e  p   r p   r     e f   r p ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>998519485467414529</td>\n",
       "      <td>@KrypsKarmaKid Tu traites qui de salope la seu...</td>\n",
       "      <td>u  r  q u  e  p   e u  p e  e     e r   p u  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>997799245464899584</td>\n",
       "      <td>Voil√† √† quoi tu dois me servir sale pute ! Ta ...</td>\n",
       "      <td>v   q u  u   e  e r v   p u   e u  u e  e  e  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                  ID  \\\n",
       "0    1.0  998206424189751296   \n",
       "1    1.0  997896508384169984   \n",
       "2    0.0                  31   \n",
       "3    0.0  998519485467414529   \n",
       "4    0.0  997799245464899584   \n",
       "\n",
       "                                               Texte  \\\n",
       "0  On m‚Äôavait sorti (pour de vrai) ¬´¬†on est tous ...   \n",
       "1  VIVE L AMOUR ‚ù§VIVE LA PAIX\\n‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§üëèüëç\\nEN...   \n",
       "2  J'me rend compte √† quel point ya trop d'noir d...   \n",
       "3  @KrypsKarmaKid Tu traites qui de salope la seu...   \n",
       "4  Voil√† √† quoi tu dois me servir sale pute ! Ta ...   \n",
       "\n",
       "                                         Texte_clean  \n",
       "0    v  r  p u r  e  v r   e  u  e g   p u   p r ...  \n",
       "1  v v   u r  v v   p x  e r e  e  p e u p  u   p...  \n",
       "2   e  r e  p   q u e  p   r p   r     e f   r p ...  \n",
       "3  u  r  q u  e  p   e u  p e  e     e r   p u  e...  \n",
       "4  v   q u  u   e  e r v   p u   e u  u e  e  e  ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_dir+'tweets_labeled_4k_cleaned.csv'\n",
    "\n",
    "tw_data = pd.read_csv(data_path)#.drop('id', axis=1).rename(columns={'label': 'Label', 'tweet': 'Texte'})\n",
    "\n",
    "# Fix labels\n",
    "labels = {'n':1, 'N':1, 'h':0, 'H':0, 'ENG':-1, 's':0, \n",
    "          'S':0, 'SH':0, 'PUB':-1, 'sh':0, 'f':-1, 'nn':1}\n",
    "\n",
    "tw_data['Label'].replace(labels, inplace=True)\n",
    "tw_data.drop(tw_data[tw_data.Label == -1].index, inplace=True) #removing ads etc.\n",
    "\n",
    "# Clean text. Youc an choose whether to remove stopwords and stem.\n",
    "# Note: use the same pre-processing used for the dataset on which w2v has been trained !\n",
    "# In particular, here I don't remove stopwords, \n",
    "# since they could change substantially the meaning of a phrase\n",
    "\n",
    "if not remove_sw:\n",
    "    tw_data['Texte_clean'] = tw_data.Texte.apply(lambda x:tweet_cleaner(x, my_dict, stem=stem))\n",
    "else:\n",
    "    tw_data['Texte_clean'] = tw_data.Texte.apply(lambda x:' '.join(remove_stopwords(\n",
    "                        tokenize(\n",
    "                        tweet_cleaner(\n",
    "                            x,\n",
    "                            my_dict,\n",
    "                            stem=stem)),\n",
    "                    generate_stopwords())))\n",
    "\n",
    "\n",
    "\n",
    "tw_data = tw_data.drop_duplicates(subset='Texte_clean')\n",
    "tw_data = tw_data.dropna()\n",
    "\n",
    "\n",
    "tw_data = tw_data.reset_index(drop=True)\n",
    "tw_data['Label'].value_counts()\n",
    "tw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_1M' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(len(model_1M.wv.index2word), \"mots ont √©t√© vectoris√©s\")\n",
    "print(\"Chaque mot est repr√©sent√© selon\", model_1M.wv.syn0[0].shape[0], \"dimensions\")\n",
    "\n",
    "words_list = []\n",
    "for tweet in list(tw_data['Texte_clean']):\n",
    "    for w in list(tweet.split()):\n",
    "        words_list.append(w)\n",
    "\n",
    "words_data = pd.DataFrame(words_list).drop_duplicates()\n",
    "\n",
    "count = 0\n",
    "for w in list(words_data[0]):\n",
    "    if w not in model_1M.wv.index2word:\n",
    "        count +=1\n",
    "\n",
    "print(count, \"mots sur\", len(words_data), \"sont dans les tweets clean et pas dans le dict w2v\")\n",
    "print(len(words_data))\n",
    "print(len(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lexical features\n",
    "tw_data = add_lexical_features(tw_data)\n",
    "lex_cols = ['nbr_characters','nbr_words', 'nbr_ats', 'nbr_hashtags', 'nbr_urls',\n",
    "            'nbr_letters','nbr_caps', 'nbr_fancy' ]\n",
    "lex_features = tw_data.as_matrix(columns=lex_cols)\n",
    "\n",
    "# w2v features, weighted\n",
    "features_1M_data = my_vectorizer_1M.transform(tw_data.Texte_clean)\n",
    "\n",
    "# w2v features, no weight\n",
    "my_vectorizer_1M_noweight = MeanEmbeddingVectorizer(w2v_1M)\n",
    "features_1M_not_weighted = my_vectorizer_1M_noweight.transform(tw_data.Texte_clean)\n",
    "\n",
    "\n",
    "\n",
    "# tfidf features. We impose a feature vector of 90% the size of the dataset, \n",
    "# so that n_features < n_data. This can be changed\n",
    "\n",
    "features_tfidf, words_freq, vocab = get_tfidf_frequencies(tw_data.Texte_clean,\n",
    "                                                            stem=True,\n",
    "                                                            remove_stopwords=False,\n",
    "                                                            ngram_range=(1,3),\n",
    "                                                          n_features = round((tw_data.shape[0]/10)*9)\n",
    "                                                         )\n",
    "\n",
    "\n",
    "# converting the 4K labeled data into one vector, \n",
    "# in order to keep only the closests to re-run w2v embedding\n",
    "labels_vector = features_1M_data.mean(axis=0)\n",
    "\n",
    "\n",
    "# Concatenation\n",
    "M_1M = np.concatenate([features_1M_data, lex_features],axis=1)\n",
    "print('w2v features dimension: %s' %str(M_1M.shape))  \n",
    "\n",
    "M_tfidf = np.concatenate([features_tfidf, lex_features],axis=1)\n",
    "print('Tf-Idf features dimension: %s' %str(M_tfidf.shape))\n",
    "\n",
    "\n",
    "M_not_weighted = np.concatenate([features_1M_not_weighted, lex_features],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select  a subset of the 1M tweets that is closer to the labels vector to re-train w2v embedding (SLOW )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Volumes/MIchi Hard /models/saved_w2vec_selected_with_stem_sw_removed_nf300_mvc1_cont10.pkl\n",
      "Transforming 1 Milion features with w2v...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_vectorizer_1M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_vectorizer_1M' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_model_name_1 = 'saved_w2vec_selected'\n",
    "full_model_name_1 = base_model_name_1+stem_str+sw_str\n",
    "\n",
    "SAVED_MODEL_1 = models_dir+full_model_name_1+'_nf'+str(num_features)+'_mvc'+str(min_word_count)\\\n",
    "            +'_cont'+str(context)+'.pkl'#+'_ds'+str(downsampling)\n",
    "\n",
    "print('Path: '+SAVED_MODEL_1 )\n",
    "    \n",
    "if not os.path.exists(SAVED_MODEL_1):\n",
    "    \n",
    "    t = current_milli_time()\n",
    "    print(\"Transforming 1 Milion features with w2v...\") # This takes ~2min\n",
    "    features_1M_1M = my_vectorizer_1M.transform(df.clean_tweets)\n",
    "    print(\"it takes about\",(current_milli_time()-t)/60000,\"minutes\")\n",
    "    \n",
    "    print(\"Re-fitting model...\")\n",
    "    t = current_milli_time()\n",
    "     \n",
    "    # measuring distances between 1M tweets baseline and the average vector\n",
    "    # of the 4K labelled tweets\n",
    "\n",
    "    norm_labels = np.linalg.norm(labels_vector)\n",
    "    norm_features = np.linalg.norm(features_1M_1M, axis=1)\n",
    "    dot = labels_vector.dot(features_1M_1M.T)\n",
    "    df['similarity'] = dot/(norm_labels*norm_features)\n",
    "    df['len'] = [len(t.split()) for t in df.clean_tweets]\n",
    "    \n",
    "    # designing a subset of the 1M tweets that is closer to the labels vector,\n",
    "    # to re-train w2v embedding\n",
    "    seuil_len = 5\n",
    "    seuil_sim = 0.5\n",
    "    df_selected = df.sort_values(by='similarity', ascending=False).drop(df[df.len<seuil_len].index)\n",
    "    df_selected = df_selected.drop(df_selected[df_selected.similarity<seuil_sim].index)\n",
    "\n",
    "    # generate documents list for training w2v\n",
    "    documents_selected = [tweet.split() for tweet in list(df_selected['clean_tweets'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model_selected = gensim.models.Word2Vec(documents_selected, \n",
    "                                      size=num_features, \n",
    "                                      window=context, \n",
    "                                      min_count=min_word_count,\n",
    "                                      workers=4)\n",
    "    model_selected.train(documents_selected, total_examples=len(documents_selected), epochs=10)\n",
    "    print(\"it takes about\",(current_milli_time()-t)/60000,\"minutes\")\n",
    "    with open(SAVED_MODEL_1, \"wb\") as f:\n",
    "        pickle.dump(model_selected, f)\n",
    "else:\n",
    "    print(\"Loading model...\")\n",
    "    with open(SAVED_MODEL_1, \"rb\") as f:\n",
    "        model_selected = pickle.load(f)\n",
    "        \n",
    "w2v_selected = dict(zip(model_selected.wv.index2word, model_selected.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Volumes/MIchi Hard /models/saved_w2vec_selected_vectorizer_with_stem_sw_removed_nf300_mvc1_cont10.pkl\n",
      "Fitting vectorizer...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w2v_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v_selected' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_vec_name_1 = 'saved_w2vec_selected_vectorizer'\n",
    "full_vec_name_1 = base_vec_name_1+stem_str+sw_str\n",
    "\n",
    "\n",
    "SAVED_VEC_1= models_dir+full_vec_name_1+'_nf'+str(num_features)+'_mvc'+str(min_word_count)\\\n",
    "            +'_cont'+str(context)+'.pkl'#+'_ds'+str(downsampling)\n",
    "\n",
    "\n",
    "print(\"Path: \"+ SAVED_VEC_1)\n",
    "        \n",
    "if not os.path.exists(SAVED_VEC_1):\n",
    "    \n",
    "    print(\"Fitting vectorizer...\")\n",
    "    # Takes ~ 10mins\n",
    "    t = current_milli_time()\n",
    "\n",
    "    my_vectorizer_selected = TfidfEmbeddingVectorizer(w2v_selected)\n",
    "    if remove_sw:\n",
    "        my_vectorizer_selected.fit(df_selected['clean_tweets'], stem=stem, rem_sw=True)\n",
    "    else:\n",
    "        my_vectorizer_selected.fit(df_selected['clean_tweets'], stem=stem, rem_sw=False)\n",
    "\n",
    "\n",
    "    print(\"it takes about\",(current_milli_time()-t)/60000,\"minutes\")\n",
    "    \n",
    "    with open(SAVED_VEC_1, \"wb\") as f:\n",
    "        pickle.dump(my_vectorizer_selected, f)\n",
    "\n",
    "else:\n",
    "    print(\"Loading vectorizer...\")\n",
    "    with open(SAVED_VEC_1, \"rb\") as f:\n",
    "          my_vectorizer_selected = pickle.load(f)\n",
    "\n",
    "\n",
    "            \n",
    "features_selected = my_vectorizer_selected.transform(tw_data.Texte_clean)\n",
    "\n",
    "M_selected = np.concatenate([features_selected,lex_features],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M_1M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_16368/936749268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_train_1M, X_test_1M, y_train_1M, y_test_1M = train_test_split(M_1M,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                                 \u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M_1M' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y = tw_data['Label']\n",
    "\n",
    "X_train_1M, X_test_1M, y_train_1M, y_test_1M = train_test_split(M_1M,\n",
    "                                                                y ,\n",
    "                                                                random_state=42, \n",
    "                                                                test_size=0.15)\n",
    "\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(M_tfidf, y ,\n",
    "                                                                            random_state=42, \n",
    "                                                                            test_size=0.15)\n",
    "\n",
    "X_train_not_weighted, X_test_not_weighted,\\\n",
    "y_train_not_weighted, y_test_not_weighted = train_test_split(M_not_weighted, \n",
    "                                                     y ,\n",
    "                                                     random_state=42, \n",
    "                                                     test_size=0.15)\n",
    "\n",
    "\n",
    "X_train_selected, X_test_selected,\\\n",
    "y_train_selected, y_test_selected = train_test_split(M_selected, \n",
    "                                                     y ,\n",
    "                                                     random_state=42, \n",
    "                                                     test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = linear_model.LogisticRegression(C=1., class_weight='balanced',penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_1M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_1M' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model_w = lr_model\n",
    "lr_model_w.fit(X_train_1M, y_train_1M)\n",
    "y_preds_w = lr_model_w.predict(X_test_1M)\n",
    "\n",
    "print(classification_report( y_test_1M, y_preds_w ))\n",
    "cm_w = print_cm(y_test_1M, y_preds_w , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_not_weighted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_not_weighted' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model_uw = lr_model\n",
    "\n",
    "lr_model_uw.fit(X_train_not_weighted, y_train_not_weighted)\n",
    "y_preds_uw = lr_model_uw.predict(X_test_not_weighted)\n",
    "\n",
    "print(classification_report( y_test_not_weighted, y_preds_uw ))\n",
    "cm_uw = print_cm(y_test_not_weighted, y_preds_uw , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_selected' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model_sw = lr_model\n",
    "\n",
    "lr_model_sw.fit(X_train_selected, y_train_selected)\n",
    "y_preds_sw = lr_model_sw.predict(X_test_selected)\n",
    "\n",
    "print(classification_report( y_test_selected, y_preds_sw ))\n",
    "cm_sw = print_cm(y_test_selected, y_preds_sw , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-Idf only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.44      0.52        73\n",
      "        1.0       0.92      0.96      0.94       473\n",
      "\n",
      "avg / total       0.88      0.89      0.88       546\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model= ensemble.RandomForestClassifier(criterion='gini')\n",
    "\n",
    "rf_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_preds_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "print(classification_report( y_test_tfidf, y_preds_rf ))\n",
    "cm_rf = print_cm(y_test_tfidf, y_preds_rf , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling+Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0.0: 545, 1.0: 545})\n",
      "(981,)\n",
      "(109,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_res, y_res, idx_res = rus.fit_sample(M_selected, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res, \n",
    "                                                     y_res ,\n",
    "                                                     random_state=42, \n",
    "                                                     test_size=0.1)\n",
    "\n",
    "print(y_res_train.shape)\n",
    "print(y_res_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.79      0.76        56\n",
      "        1.0       0.76      0.70      0.73        53\n",
      "\n",
      "avg / total       0.74      0.74      0.74       109\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "lr_model_us = lr_model\n",
    "\n",
    "lr_model_us.fit(X_res_train, y_res_train)\n",
    "y_preds_us = lr_model_us.predict(X_res_test)\n",
    "\n",
    "print(classification_report( y_res_test, y_preds_us ))\n",
    "cm_us = print_cm(y_res_test, y_preds_us , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "Weighted features seem to do better. So, the higher evaluation time is worth. \n",
    "Also, w2v with tf-idf weights does significantly better than Tf-Idf alone.\n",
    "On the other hand, it is not completely clear if using selected features gives better performance.\n",
    "In the following, we will optimize using w2v features with tf-idf weights, and compare features obtained from selected and full sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid parameter search\n",
    "####  As a metric, we maximise recall for class \"H\" (it is better to predict an \"H\" which is actually an \"N\" than the contrary). The function custom_recall does this and will be used as evaluation metric to choose the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_recall(y_true, y_pred): \n",
    "    ''' Computes recall only on labels 0 '''\n",
    "    rec = recall_score(y_true, y_pred, labels=[0], pos_label=0, average='binary')\n",
    "    return rec #target_accuracy\n",
    "\n",
    "my_scorer = make_scorer(custom_recall)\n",
    "\n",
    "\n",
    "\n",
    "def my_pipeline(my_clf, x_train, x_test , y_train, y_test, scorer, parameters):\n",
    "\n",
    "    pipeline = Pipeline([('clf', my_clf)])\n",
    "\n",
    "    nn = x_train.shape[0]\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,verbose=1, scoring=scorer)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print ('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print ('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    predictions = grid_search.predict(x_test)\n",
    "    print (classification_report(y_test, predictions))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - weighted features from full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_init = linear_model.LogisticRegression(C=1., class_weight='balanced',penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters_lr = {\n",
    "        #'clf__penalty': ('l1', 'l2'),\n",
    "        'clf__C': np.linspace(1, 10, 2),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class_LR_w = my_pipeline(lr_init, \n",
    "                       X_train_1M, X_test_1M, y_train_1M, y_test_1M,\n",
    "                       my_scorer , parameters_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_w = print_cm(y_test_1M, class_LR_w.predict(X_test_1M) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - weighted features from selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters_lr = {\n",
    "        #'clf__penalty': ('l1', 'l2'),\n",
    "        'clf__C': np.linspace(1, 10, 2),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class_LR_selected = my_pipeline(lr_init, \n",
    "                       X_train_selected, X_test_selected, y_train_selected, y_test_selected,\n",
    "                       my_scorer , parameters_lr)\n",
    "\n",
    "print_cm(y_test_selected, class_LR_selected.predict(X_test_selected) , ['H','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_selected = print_cm(y_test_selected, class_LR_w.predict(X_test_selected) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - unweighted features from full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters_lr = {\n",
    "        'clf__penalty': ('l1', 'l2'),\n",
    "        'clf__C': np.linspace(1, 10, 2),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class_LR_uw = my_pipeline(linear_model.LogisticRegression(C=1., \n",
    "                                                       class_weight='balanced'\n",
    "                                                       ), \n",
    "                       X_train_not_weighted, X_test_not_weighted,\n",
    "                          y_train_not_weighted, y_test_not_weighted,\n",
    "                       my_scorer , parameters_lr)\n",
    "\n",
    "print_cm(y_test_not_weighted, class_LR_uw.predict(X_test_not_weighted) , ['H','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_uw = print_cm(y_test_not_weighted, class_LR_uw.predict(X_test_not_weighted) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest + TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_rf = {\n",
    "        'clf__criterion': ('gini', 'entropy'),\n",
    "        'clf__max_depth': (None, 10, 100),\n",
    "        'clf__min_samples_leaf':(1,5,10)\n",
    "    }\n",
    "\n",
    "class_RF = my_pipeline(ensemble.RandomForestClassifier(n_jobs=-1, random_state=321),\n",
    "                       X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf,\n",
    "                       my_scorer, parameters_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_RF = print_cm(y_test_tfidf, class_RF.predict(X_test_tfidf) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters_lr = {\n",
    "       'clf__penalty': ('l1', 'l2'),\n",
    "        'clf__C': np.linspace(1, 10, 2),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "class_LR_us = my_pipeline(linear_model.LogisticRegression(C=1.), \n",
    "                       X_res_train, X_res_test, y_res_train, y_res_test,\n",
    "                       my_scorer , parameters_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cm(y_res_test, class_LR_us.predict(X_res_test) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Very promising but results can fluctuate a lot depending on the sampling. Must add k-fold cross validation !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other trials (no luck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model= svm.SVC(C=1, kernel='rbf', gamma=0.1)\n",
    "\n",
    "svm_model.fit(X_train_1M, y_train_1M)\n",
    "y_preds = svm_model.predict(X_test_1M)\n",
    "\n",
    "print(classification_report( y_test_1M, y_preds ))\n",
    "print_cm(y_test_1M, y_preds , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_model= ensemble.RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
    "\n",
    "rf_model.fit(X_train_1M, y_train_1M)\n",
    "y_preds = rf_model.predict(X_test_1M)\n",
    "\n",
    "print(classification_report( y_test_1M, y_preds ))\n",
    "print_cm(y_test_1M, y_preds , ['H','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters_svm = {\n",
    "        'clf__gamma': (0.0001, 0.001, 0.01),\n",
    "        'clf__C': (100, 150, 500),\n",
    "        #'clf__kernel':('rbf', 'linear','sigmoid' )\n",
    "    }\n",
    "\n",
    "class_SVM = my_pipeline(svm.SVC(C=100, kernel='rbf'),\n",
    "                        X_train_1M, X_test_1M, y_train_1M, y_test_1M,\n",
    "                       my_scorer , parameters_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cm(y_test_1M, class_SVM.predict(X_test_1M) , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, metric='chebyshev')\n",
    "\n",
    "knn.fit(X_train_1M, y_train_1M)\n",
    "y_pred_1M = knn.predict(X_test_1M)\n",
    "\n",
    "print_cm(y_test_1M, y_pred_1M , ['H','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10, metric='minkowski')\n",
    "\n",
    "knn.fit(X_res_train, y_res_train)\n",
    "y_pred_us = knn.predict(X_res_test)\n",
    "\n",
    "print_cm(y_res_test, y_pred_us , ['H','N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our conclusion: the best model is Logistic REgression with l1 reg. and C=1 .\n",
    "It seem to work (slightly) better with  w2v trained on the full sample rather than on the selected sample (why? Because the selected sample it's trained with less data? ). However, the difference is tiny and more investigation seems important (e.g trying cross-validation).\n",
    "\n",
    "\n",
    "If we use a Tf-Idf vectorizer, we get that the best classifier is a Random Forest with gini criterion. This does considerably worse that w2v+log reg if we consider the False positive rate (predicted =N but true=H ), and better if we consider the false negative (predicted=H but true=N). \n",
    "Since it's better to minimize false positive rate, we conclude that w2v works better.  \n",
    "\n",
    "Finally, using undersampling techniques seems to improve the performace, in particular on the false positive rate, even if the size of the dataset is highly reduced. Given the small amount of data available, however, this risks to worsen the classifier's performance when applied to previously unseen data, and also the performance can fluctuate considerably when changing subsampling. However, this result is interesting to keep in mind if one has a larger dataset.\n",
    "\n",
    "#### In general, to better comment performance we need to cross-validate ! Otherwise the results fluctuate too much (this is natural given the nature of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL = models_dir+\"saved_lr_1M.pkl\"\n",
    "with open(SAVED_MODEL, \"wb\") as f:\n",
    "    pickle.dump(class_LR, f)\n",
    "\n",
    "SAVED_MODEL = models_dir+\"saved_lr_selected.pkl\"\n",
    "with open(SAVED_MODEL, \"wb\") as f:\n",
    "    pickle.dump(class_LR_selected, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\", style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" > Practice Python </h1> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "* pour ajouter une cellule utiliser esc + a\n",
    "* pour supprimer une cellule utiliser esc + x (faire attention)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
